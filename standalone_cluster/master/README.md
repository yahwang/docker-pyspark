### docker-pyspark-standalone-master

- can get data from AWS S3 using s3a

    - need to set "spark.hadoop.fs.s3a.access.key" and "spark.hadoop.fs.s3a.secret.key" 

- python packages installed

    - jupyter==1.2.3
    - pandas==0.25.3
    - numpy==1.17.4
    - pyarrow==0.14.1

